import streamlit as st
import pandas as pd
import langchain 
#from openai import OpenAI
from langchain_openai import OpenAI
from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.document_loaders import DataFrameLoader
from langchain_core.vectorstores import InMemoryVectorStore

# Show title and description.
st.title("üìÑ –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Ç–µ–∫—Å—Ç—É")
#st.write(
#    "Upload a document below and ask a question about it ‚Äì GPT will answer! "
openai_api_key = st.secrets["OPENAI_API_KEY"]
if not openai_api_key:
    st.info("Please add your OpenAI API key to continue.", icon="üóùÔ∏è")
else:

    # Create an OpenAI client.
    client = OpenAI(api_key=openai_api_key)
#    embeddings_ai = client.embeddings.create(input = "Test", model="text-embedding-3-small")
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    model = st.selectbox(
      "–í—ã–±–µ—Ä–∏—Ç–µ –ò–ò –º–æ–¥–µ–ª—å:",
      ("gpt-4.1", "o4-mini", "gpt-4o"),
    )
    llm = ChatOpenAI(model=model)
    # Let the user upload a file via `st.file_uploader`.
    uploaded_file = st.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≤–æ–π —Ç–µ–∫—Å—Ç –∑–¥–µ—Å—å (.txt –∏–ª–∏ .md)", type=("txt", "md")
    )
    # 
    input_text = st.text_area(
        "–õ–∏–±–æ —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ —Å–≤–æ–π —Ç–µ–∫—Å—Ç –ø—Ä—è–º–æ —Å—é–¥–∞:",
        placeholder=" ",
    #    disabled= uploaded_file,
    )
    
    st.divider()
# –§–æ—Ä–º–∞ –¥–ª—è –≤–≤–æ–¥–∞ –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    with st.form("question_form"):
        question = st.text_input("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ —Ç–µ–∫—Å—Ç—É:", "")
        q_submitted = st.form_submit_button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å")
    if q_submitted:
        if uploaded_file: 
           # Process the uploaded file and question.
           document = uploaded_file.read().decode()
        elif input_text:
           # Process input text and question.
           document = input_text
        messages = [
            {"role": "system", "content": f"–û—Ç–≤–µ—á–∞–π –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞"},
            {"role": "user", "content": f"–î–æ–∫—É–º–µ–Ω—Ç: {document} \n\n---\n\n {question}",}
        ]
        ai_msg = llm.invoke(messages)
       
        # Generate an answer using the OpenAI API.
        #stream = llm.chat.completions.create(
        #      model=model,
        #      messages=messages,
        #      stream=True,
        #  )
        # Stream the response to the app using `st.write_stream`.
        #st.write_stream(stream)
    st.divider()


